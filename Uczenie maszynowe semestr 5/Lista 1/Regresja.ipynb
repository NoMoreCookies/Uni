{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8bc1ae1",
   "metadata": {},
   "source": [
    "Importowanie bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6c4bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytest\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2bf614",
   "metadata": {},
   "source": [
    "$ \\frac{1}{2}\\sum_{i=1}^{n}{(y_i-\\hat{f}{(x_i)})}^2 $ \\\n",
    "Gdzie to jest równe \\\n",
    "$ \\frac{1}{2}\\sum_{i=1}^{n}{(y_i-{\\beta}_0-{{\\beta}_1}x_{i1}-{{\\beta}_2}x_{i2}-...-{{\\beta}_n}x_{in}) }^2 $ \\\n",
    "Cel: Znaleźć ${\\beta}_0,{\\beta}_1 ...itd$ dla których $L(\\beta)$ jest minimalna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d819777",
   "metadata": {},
   "source": [
    "Można uzupełnić wszystkie X jedynką z przodu ${\\hat{x}_i=(1,x_{i,1},\\cdots,1,x_{i,m})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd79499",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "y_1 \\\\\n",
    "\\vdots \\\\\n",
    "y_n\n",
    "\\end{pmatrix}\n",
    "\n",
    "\\approx\n",
    "\n",
    "\\begin{pmatrix}\n",
    "\\hat{f}{({\\hat{x}}_1)} \\\\\n",
    "\\vdots \\\\\n",
    "\\hat{f}{({\\hat{x}}_n)}\n",
    "\\end{pmatrix}\n",
    "\n",
    "=\n",
    "\n",
    "\\begin{pmatrix}\n",
    "{1 \\space x_{1,1} \\space \\cdots \\space x_{1,m}} \\\\\n",
    "\\vdots \\\\\n",
    "{1 \\space x_{n,1} \\space \\cdots \\space x_{n,m}}\n",
    "\\end{pmatrix}\n",
    "\n",
    "\\begin{pmatrix}\n",
    "{\\beta}_0 \\\\\n",
    "\\vdots \\\\\n",
    "{\\beta}_m \n",
    "\\end{pmatrix}\n",
    "\n",
    "=\n",
    "\n",
    "\\begin{pmatrix}\n",
    "{{\\beta}_0 + {\\beta}_1{\\space x_{1,1}} + \\space \\cdots \\space  + {\\beta}_m{x_{1,m}}} \\\\\n",
    "\\vdots \\\\\n",
    "{{\\beta}_0 + {\\beta}_1{\\space x_{n,1}} + \\space \\cdots \\space  + {\\beta}_m{x_{n,m}}}\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d82da9c",
   "metadata": {},
   "source": [
    "$$\n",
    "\\beta = {(X^{T}X)}^{-1}X^{T}y\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd2232",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class LinearRegr:\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"Finds theta minimizing the squared cost function L using the formula.\n",
    "        \n",
    "        Args:\n",
    "            self: LinearRegr object\n",
    "            X (np.array): shape = (n, m)\n",
    "            Y (np.array): shape = (n)\n",
    "\n",
    "        Returns:\n",
    "            self with minimalized theta\n",
    "        \n",
    "        Notes:\n",
    "            Before applying the formula to X, a column of ones should be added.\n",
    "            Function definitions taken from https://www.statlearning.com\n",
    "        \"\"\"\n",
    "        n, m = X.shape\n",
    "\n",
    "        X = np.hstack((np.ones((n,1)),X))\n",
    "\n",
    "        p1 = np.linalg.inv(X.transpose() @ X)\n",
    "        p2 = p1 @ X.transpose()\n",
    "        p3 = p2 @ Y\n",
    "    \n",
    "        self.theta = p3\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Zwraca przewidywane wartosci funkcji dla kazdego wiersza macierzy X.\n",
    "        \"\"\"\n",
    "        n, m = X.shape\n",
    "        X = np.hstack((np.ones((n,1)),X))\n",
    "        Y = np.matmul(X, self.theta)\n",
    "        \n",
    "        return Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fcf77487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_RegressionInOneDim():\n",
    "    X = np.array([1,3,2,5]).reshape((4,1))\n",
    "    Y = np.array([2,5, 3, 8])\n",
    "    a = np.array([1,2,10]).reshape((3,1))\n",
    "    expected = LinearRegression().fit(X, Y).predict(a)\n",
    "    actual = LinearRegr().fit(X, Y).predict(a)\n",
    "    assert list(actual) == pytest.approx(list(expected))\n",
    "\n",
    "def test_RegressionInThreeDim():\n",
    "    X = np.array([1,2,3,5,4,5,4,3,3,3,2,5]).reshape((4,3))\n",
    "    Y = np.array([2,5, 3, 8])\n",
    "    a = np.array([1,0,0, 0,1,0, 0,0,1, 2,5,7, -2,0,3]).reshape((5,3))\n",
    "    expected = LinearRegression().fit(X, Y).predict(a)\n",
    "    actual = LinearRegr().fit(X, Y).predict(a)\n",
    "    assert list(actual) == pytest.approx(list(expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5e24e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_RegressionInOneDim()\n",
    "\n",
    "test_RegressionInThreeDim()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
