---
title: "Sprawozdanie 1"
subtitle: "Analiza przeżycia"
author: "Marta Stankiewicz (282244) \n Kacper Szmigielski (282255)"
header-includes:
   - \usepackage[OT4]{polski}
   - \usepackage[utf8]{inputenc}
   - \usepackage{graphicx}
   - \usepackage{float}
output: 
  pdf_document:
    toc: true
    fig_caption: true
    fig_width: 5 
    fig_height: 4 
    number_sections: true
fontsize: 12pt 
lof: true
lot: true
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = FALSE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
knitr::opts_chunk$set(fig.pos = "H", out.extra ='', fig.align = "center")

```

# Lista 1

```{r libraries_import}
library(ggplot2)
library(dplyr)
library(tidyr)
library(xtable)
library(ggplot2)
library(dplyr)
library(tidyr)
library(xtable)
library(survival)
library(survminer)
library(survRM2)
set.seed(123)
```

## Zadanie 1

Gęstość funkcji $$
f(t,\alpha,\beta,\gamma)=
\frac{\alpha\gamma}{\beta}
\left(\frac{t}{\beta}\right)^{\alpha-1}
\left[1-\exp\!\left(-\left(\frac{t}{\beta}\right)^{\alpha}\right)\right]^{\gamma-1}
\exp\!\left(-\left(\frac{t}{\beta}\right)^{\alpha}\right)\,
\mathbf{1}_{(0,\infty)}(t).
$$

```{r gęstość_f,echo = TRUE}

density_weib <- function(x, alpha, beta, gamma) {
  dens <- ifelse(
    x > 0,
    (alpha * gamma / beta) *
      (x / beta)^(alpha - 1) *
      (1 - exp(-(x / beta)^alpha))^(gamma - 1) *
      exp(-(x / beta)^alpha),
    0
  )
  return(dens)
}

```

Dystrybuanta funkcji

$$
F(t,\alpha,\beta,\gamma)=
\begin{cases}
\left[1-\exp\!\left(-\left(\dfrac{t}{\beta}\right)^{\alpha}\right)\right]^{\gamma}, & t\ge 0,\\[6pt]
0, & t<0~.
\end{cases}
$$

```{r dyst_funkcji,echo = TRUE}

distrib_weib <- function(x, alpha, beta, gamma){
  dist <- (1-exp(-(x/beta)^alpha))^gamma
  return(dist)
}

```

Funkcja hazardu

$$
h(t,\alpha,\beta,\gamma)
= \frac{f(t,\alpha,\beta,\gamma)}{1 - F(t,\alpha,\beta,\gamma)}
= \frac{f(t,\alpha,\beta,\gamma)}{S(t)} ,
$$

```{r f_hazardu,echo = TRUE}

haz_weib <- function(x, alpha, beta, gamma){
  haz <- density_weib(x, alpha, beta, gamma) / 
    (1 - distrib_weib(x, alpha, beta, gamma))
  return(haz)
}

```

Funkcja kwantylowa (odwrotnej dystrybuanty)

$$
Q(p;\alpha,\beta,\gamma)
= \beta\left[-\ln\!\Big(1-p^{1/\gamma}\Big)\right]^{1/\alpha},
\qquad 0<p<1,
$$

```{r f_kwantylowa,echo = TRUE}

quant_weib <- function(p, alpha, beta, gamma){
  quant <- beta * (-log(1 - p^(1 / gamma)))^(1 / alpha)
  return(quant)
}

```

Funkcje zostały napisane zgodnie z definicjami

## Zadanie 2


### Wykresy Weibulla {#wykres_weib}

```{r zadanie2,fig.cap = "Wykresy Weibulla"}

xvalue <- seq(0.3, 10, 0.05)
yvalue1 <- haz_weib(xvalue, 1/2, 2, 3/4)
yvalue2 <- haz_weib(xvalue, 1, 2, 1)
yvalue3 <- haz_weib(xvalue, 3/2, 3, 3)
yvalue4 <- haz_weib(xvalue, 3/2, 4, 1/8)
yvalue5 <- haz_weib(xvalue, 3/4, 1, 2)

data1 <- data.frame(xvalue, yvalue1) 
data2 <- data.frame(xvalue, yvalue2) 
data3 <- data.frame(xvalue, yvalue3) 
data4 <- data.frame(xvalue, yvalue4) 
data5 <- data.frame(xvalue, yvalue5) 

labels <- c(
  expression(gamma == 0.5 ~ "," ~ beta == 2 ~ "," ~ alpha == 3/4),
  expression(gamma == 1 ~ "," ~ beta == 2 ~ "," ~ alpha == 1),
  expression(gamma == 3/2 ~ "," ~ beta == 3 ~ "," ~ alpha == 3),
  expression(gamma == 3/2 ~ "," ~ beta == 4 ~ "," ~ alpha == 1/8),
  expression(gamma == 3/4 ~ "," ~ beta == 1 ~ "," ~ alpha == 2)
)

hazard_plot <- ggplot() + geom_line(data=data1, aes(x=xvalue, y=yvalue1, color='A')) + 
  geom_line(data=data2, aes(x=xvalue, y=yvalue2, color='B')) + 
  geom_line(data=data3, aes(x=xvalue, y=yvalue3, color='C')) + 
  geom_line(data=data4, aes(x=xvalue, y=yvalue4, color='D')) + 
  geom_line(data=data5, aes(x=xvalue, y=yvalue5, color='E')) +
  scale_color_manual(values=c('A'='yellow', 'B'='blue', 'C'='magenta', 'D'='green', 'E'='red'),
                     labels = labels) +
  theme(legend.position = "right") + xlim(0,10) + ylim(0,1) + theme_minimal() + 
  labs(y="hazard", x="x", title = "Funkcja hazardu z uogólnionego rozkładu Weibulla")

print(hazard_plot)

```

[Wykresy](#wykres_weib) dla odpowiednich parametrów są zgodne z przedstawionymi na labolatoriach

## Zadanie 3

Dane są generowane przy użyciu metody odwrotnej dystrybuanty ( u nas funkcji kwatylowej)

```{r generator, echo = TRUE}

number_generator <- function(n, alpha, beta, gamma){
  u <- runif(n)  # losujemy z U(0,1)
  x <- quant_weib(u, alpha, beta, gamma)  
  return(x)
}

```

## Zadanie 4

### Histogramy oraz gęstości {#wykresy}
```{r zad 4,fig.cap = "Badanie rozkładu histogramów"}
mala_p <- number_generator(50, 1, 2, 1)
mala_d <- number_generator(50, 1/2, 2, 3/8)
duza_p <- number_generator(100, 1, 2, 1)
duza_d <- number_generator(100, 1/2, 2, 3/8)

par(mfrow = c(2, 2))

labels <- c(
  expression(gamma == 0.5 ~ "," ~ beta == 2 ~ "," ~ alpha == 3/4),
  expression(gamma == 1 ~ "," ~ beta == 2 ~ "," ~ alpha == 1),
  expression(gamma == 3/2 ~ "," ~ beta == 3 ~ "," ~ alpha == 3),
  expression(gamma == 3/2 ~ "," ~ beta == 4 ~ "," ~ alpha == 1/8),
  expression(gamma == 3/4 ~ "," ~ beta == 1 ~ "," ~ alpha == 2)
)


# small_p
hist(mala_p, probability = TRUE, col = "lightblue", main = labels[1],xlab = "n = 50",ylab = "density")
x_vals <- seq(min(mala_p), max(mala_p), length.out = 100)
lines(x_vals, density_weib(x_vals, gamma = 1, beta = 2, alpha = 1), col = "deeppink", lwd = 2)

# small_d
hist(mala_d, probability = TRUE, col = "lightblue", main = labels[2],xlab = "n = 50",ylab = "density")
x_vals <- seq(min(mala_d), max(mala_d), length.out = 100)
lines(x_vals, density_weib(x_vals, gamma = 1/2, beta = 2, alpha = 3/8), col = "deeppink", lwd = 2)

# large_p
hist(duza_p, probability = TRUE, col = "lightblue", main = labels[3],xlab = "n = 100",ylab = "density")
x_vals <- seq(min(duza_p), max(duza_p), length.out = 100)
lines(x_vals, density_weib(x_vals, gamma = 1, beta = 2, alpha = 1), col = "deeppink", lwd = 2)

# large_d
hist(duza_d, probability = TRUE, col = "lightblue", main = labels[4],xlab = "n = 100",ylab = "density")
x_vals <- seq(min(duza_d), max(duza_d), length.out = 100)
lines(x_vals, density_weib(x_vals, gamma = 1/2, beta = 2, alpha = 3/8), col = "deeppink", lwd = 2)

```

Dla n = 100 [histogramy](#wykresy) są lepiej dopasowane do wykresów gęstości rozkładów.
Co jest zgodne z intuicją, biorąc pod uwagę fakt, że dane są generowane z tych rozkładów.

## Zadanie 5

### Podstawowe wskaźniki opisowe {#podst_wsk_opis}
```{r zadanie 5,results='asis'}

statystyki_weib <- function(dane, alpha, beta, gamma, nazwa){
  srednia <- mean(dane)
  mediana_emp <- median(dane)
  sd_emp <- sd(dane)
  kw1_emp <- quantile(dane, 0.25)
  kw3_emp <- quantile(dane, 0.75)
  min_emp <- min(dane)
  max_emp <- max(dane)
  
  mediana_teor <- quant_weib(0.5, alpha, beta, gamma)
  kw1_teor <- quant_weib(0.25, alpha, beta, gamma)
  kw3_teor <- quant_weib(0.75, alpha, beta, gamma)
  
  data.frame(
    Args = nazwa,
    Mean = srednia,
    Med_emp = mediana_emp,
    Med = mediana_teor,
    SD = sd_emp,
    Q1_em = kw1_emp,
    Q1_tr = kw1_teor,
    Q3_em = kw3_emp,
    Q3_tr = kw3_teor,
    Min = min_emp,
    Max = max_emp,
    rozstęp = max_emp - min_emp,
    stringsAsFactors = FALSE
  )
}

tab_stat <- rbind(
  statystyki_weib(mala_p, 1, 2, 1, "Zestaw 1"),
  statystyki_weib(mala_d, 1/2, 2, 3/8,"Zestaw 2"),
  statystyki_weib(duza_p, 1, 2, 1,"Zestaw 3"),
  statystyki_weib(duza_d, 1/2, 2, 3/8,"Zestaw 4")
)

num_cols <- sapply(tab_stat, is.numeric)
tab_stat[num_cols] <- lapply(tab_stat[num_cols], function(x) round(x, 4))

tab_xtable <- xtable(tab_stat, caption = "Statystyki dla rozkładu Weibulla", label = "tab:weibull_stats")

print(tab_xtable, include.rownames = FALSE, caption.placement = "top",comment = FALSE)


```

Zestaw 1 : $\alpha = 1$ $\beta = 2$ $\gamma = 1$ n = 50 \| Zestaw 3 : $\alpha = 1$ $\beta = 2$ $\gamma = 1$ n = 100

Zestaw 2 : $\alpha = \frac{1}{2}$ $\beta = 2$ $\gamma = \frac{3}{8}$ n = 50 \| Zestaw 4 : $\alpha = \frac{1}{2}$ $\beta = 2$ $\gamma = \frac{3}{8}$ n = 100

Dla większej [próby](#podst_wsk_opis) widać dokładniejsze kwantyle bardziej zbliżone do ich teoretycznej wartości, niż dla próby mniejszej.Jedynie w zestawie pierwszym, Q3 jest bliższe teoretycznej wartości niż w zestawie 3, jest to zapewno spowodowane losowością danych oraz dość małą próbą (50 i 100).

# Lista 2

## Zadanie 1

Funckja została napisana zgodnie z wytycznymi zadania

```{r zad1,echo = TRUE}

#--------------------------Generatory-------------------------------
gen1 <- function(n, alpha, lambda, t0){
  y <- runif(n)
  x <- - (1/lambda)*log(1- y^(1/alpha))
  
  delta <- ifelse(x <= t0, 1, 0)
  x_obs <- pmin(x, t0)
  
  return(data.frame(x = x_obs, delta = delta))
}

gen2 <- function(n, alpha, lambda, m) {
  y <- runif(n)
  x <- - (1/lambda)*log(1- y^(1/alpha))
  
  x <- sort(x)
  x_cenz <- x[m]
  
  x <- c(x[1:m], rep(x_cenz, n-m))
  delta <- c(rep(1,m), rep(0, n-m))
  
  return(data.frame(x, delta))
}


gen3 <-  function(n, alpha, lambda, eta){
  y <- runif(n)
  x <- - (1/lambda)*log(1- y^(1/alpha))
  c <- rexp(n, rate=1/eta)
  x <- pmin(x, c)
  delta <- ifelse(x==c, 0, 1)
  
  return(data.frame(x, delta))
}
#-------------------------------------------------------------------------
```

## Zadanie 2
### Podstawowe wskaźniki opisowe dla danych cenzurowanych {#podst_wsk_opis_z2}
```{r zad2,results='asis'}

wygeneruj_zm_opisowe <- function(values){
  
  
  censored <-1 - values$delta
  values <-  values$x
  
  results <- data.frame(
  Q1 = quantile(values,1/4),
  Q2 = quantile(values,1/2),
  Q3 = quantile(values,3/4),
  RANGE = diff(range(values)),
  IQR = quantile(values,3/4)-quantile(values,1/4),
  CENSORED = sum(censored),
  NCENSORED = length(censored)-sum(censored))
  return (results)
}

df1 <- wygeneruj_zm_opisowe(gen1(n=20, alpha = 1.2, lambda = 1, t0=1.67))
df2 <- wygeneruj_zm_opisowe(gen2(n=20, alpha = 1.2, lambda = 1,m=12))
df3 <- wygeneruj_zm_opisowe(gen3(n=20, alpha = 1.2, lambda = 1, eta = 1.8))

df_all <- rbind(df1,df2,df3)
rownames(df_all) <- c("Cenz 1 typu","Cenz 2 typu","Cenz los")
n <- length(colnames(df1))
digits_vec <- c(0,rep(4, n - 2), 0, 0)
tab <- xtable(df_all,digits = digits_vec, caption = "Statystyki opisowe dla wygenerowanych danych cenzurowanych") 
print(tab,type = "latex",comment = FALSE,table.placement = "H",caption.placement = "top")
```

Z [tabeli](#podst_wsk_opis_z2) widać, że sposób cenzurowania wpływa na charakterystykę danych.\
Dla cenzurowania typu pierwszego wartości kwartylowe są umiarkowane, a rozstęp (RANGE = `r round(df1$RANGE,4)`) i IQR = `r round(df1$IQR,4)` wskazują na dość duże zróżnicowanie danych.
W porównaniu z innymi typami, dane te są bardziej rozproszone niż przy cenzurowaniu typu drugiego, ale mniej zróżnicowane niż przy cenzurowaniu losowym.\
Cenzurowanie typu drugiego daje najwyższą medianę (Q2 = `r round(df2$Q2,4)`), co sugeruje przesunięcie wartości w stronę większych obserwacji.\
Z kolei cenzurowanie losowe ma najniższe kwartyle i najwyższy zakres, co wskazuje na większe rozproszenie i obecność mniejszych wartości w próbie.\
Różnice w liczbie danych ocenzurowanych i nieocenzurowanych między typami są niewielkie, więc każdy rodzaj cenzurowania wpływa głównie na rozkład, a nie na liczność danych.

## Zadanie 3
### Podstawowe wskaźniki opisowe dla danych cenz {#podst_wsk_opis_z3}
```{r zad3,results='asis'}

times_A <- c(0.03345514, 0.08656403, 0.08799947, 0.24385821, 0.27755032,
             0.40787247, 0.58825664, 0.64125620, 0.90679161, 0.94222208,rep(1,10))

times_B <- c(0.03788958, 0.12207257, 0.20319983, 0.24474299, 0.30492413,
             0.34224462, 0.42950144, 0.44484582, 0.63805066, 0.69119721,rep(1,10))

wygeneruj_zm_opisowe <- function(values){
 
  
  
  results <- data.frame(
  Q1 = quantile(values,1/4),
  Q2 = quantile(values,1/2),
  Q3 = quantile(values,3/4),
  RANGE = diff(range(values)),
  IQR = quantile(values,3/4)-quantile(values,1/4),
  CENSORED = 10,
  NCENSORED = 10
  )
  return (results)
}

df1 <- wygeneruj_zm_opisowe(times_A)
df2 <- wygeneruj_zm_opisowe(times_B)

df_all <- rbind(df1,df2)
rownames(df_all) <- c("lek A","lek B")
n <- length(colnames(df1))
digits_vec <- c(0,rep(4, n - 2), 0, 0)
tab <- xtable(df_all,digits = digits_vec,caption = "Statystyki opisowe dla danych dotyczących leków ") 
print(tab,type = "latex",comment = FALSE,table.placement = "H",caption.placement = "top")

```

Na podstawie [tabeli](#podst_wsk_opis_z3) widać, że Q2 i zakres (range) są niższe w grupie B, co może wskazywać na szybsze działanie leku oraz mniejsze zróżnicowanie wyników związane z indywidualnymi predyspozycjami biologicznymi badanych osób.
W obu grupach wartość Q3 wynosi 1, co jest zrozumiałe, ponieważ połowa obserwacji została ocenzurowana.

# Lista 3

## Zadanie 1a

```{r oszacowania NW,echo = TRUE}

X_A <- c(0.03345514, 0.08656403, 0.08799947, 0.24385821,
         0.27755032,0.40787247, 0.58825664, 0.64125620,
         0.90679161, 0.94222208, rep(1,10))
X_B <- c(0.03788958, 0.12207257, 0.20319983, 0.24474299,
         0.30492413,0.34224462, 0.42950144, 0.44484582,
         0.63805066, 0.69119721, rep(1, 10))
t <- 1
n <- 20
R_A <- sum(X_A < t)
R_B <- sum(X_B < t) 
T_A <- sum(X_A[1:10]) + t*(n-R_A)
T_B <- sum(X_B[1:10]) + t*(n-R_B)

theta_hat_A <- R_A / T_A
theta_hat_B <- R_B / T_B

theta_wave <- - log(1-R_A/n)/t

mi_hat_A <- 1/theta_hat_A
mi_hat_B <- 1/theta_hat_B
mi_wave <- 1/theta_wave

```

Na podstawie danych opisanych w zadaniu 3 z listy 2, przyjmując, że są one realizacjami zmiennych z rozkładu wykładniczego można wyznaczyć oszacowania największej wiarogodności średniego czasu do remisji choroby dla pacjentów leczonych lekiem A oraz pacjentów leczonych lekiem B.
W tym celu skorzystano ze wzorów podanych na Wykładzie 3:

$$
\hat{\vartheta} = \frac{R}{T_1} \quad
$$ gdzie

$$
T_1 = \sum_{i=1}^{R} X_{(i)} + t_0 (n - R)
$$ gdzie zmienna losowa $R$ jest losową liczbą obserwacji niecenzurowanych (kompletnych) w przedziale $(0, t_0]$. Oszacowanie NW średniego czasu do remisji choroby pacjentów leczonych lekiem A wynosi *`r round(theta_hat_A, 4)`* natomiast oszacowanie to w przypadku leku B wynosi *`r round(theta_hat_B, 4)`*.
Na podstawie uzyskanych oszacowań średniego czasu do remisji, lek A wydaje się lepszym wyborem, gdyż charakteryzuje się krótszym (mniejszym) średnim czasem do wystąpienia remisji w porównaniu z lekiem B.

## Zadanie 1b

```{r real_przedzialu_uf,echo = TRUE}
library(binom)
T.L.1.A <- binom.confint(R_A, n, methods = 'exact', 
                         conf.level = 1-0.05)$lower
T.U.1.A <- binom.confint(R_A, n, methods = 'exact', 
                         conf.level = 1-0.05)$upper

T.L.A1 <- - log(1-T.L.1.A)/t
T.U.A1 <- - log(1-T.U.1.A)/t

upp_A_1 <- 1/T.L.A1
low_A_1 <- 1/T.U.A1

T.L.2.A <- binom.confint(R_A, n, methods = 'exact',
                         conf.level = 1-0.01)$lower
T.U.2.A <- binom.confint(R_A, n, methods = 'exact',
                         conf.level = 1-0.01)$upper

T.L.A2 <- - log(1-T.L.2.A)/t
T.U.A2 <- - log(1-T.U.2.A)/t

upp_A_2 <- 1/T.L.A2
low_A_2 <- 1/T.U.A2

T.L.1.B <- binom.confint(R_B, n, methods = 'exact',
                         conf.level = 1-0.05)$lower
T.U.1.B <- binom.confint(R_B, n, methods = 'exact',
                         conf.level = 1-0.05)$upper

T.L.B1 <- - log(1-T.L.1.B)/t
T.U.B1 <- - log(1-T.U.1.B)/t

upp_B_1 <- 1/T.L.B1
low_B_1 <- 1/T.U.B1

T.L.2.B <- binom.confint(R_B, n, methods = 'exact',
                         conf.level = 1-0.01)$lower
T.U.2.B <- binom.confint(R_B, n, methods = 'exact', 
                         conf.level = 1-0.01)$upper

T.L.B2 <- - log(1-T.L.2.B)/t
T.U.B2 <- - log(1-T.U.2.B)/t

upp_B_2 <- 1/T.L.B2
low_B_2 <- 1/T.U.B2

```
### Tabela przedziałów {#taela1}
```{r tabela_przedzialy, results='asis', echo=FALSE}
library(knitr)

tabela <- data.frame( Lek = c("A", "A", "B", "B"), 
                      alpha = c(0.05, 0.01, 0.05, 0.01), 
                      Dolna_granica = c(low_A_1, low_A_2, low_B_1, low_B_2),
                      Górna_granica = c(upp_A_1, upp_A_2, upp_B_1, upp_B_2) ) 

kable(tabela, caption = "Realizacja przedziału ufności dla średniego czasu do remisji choroby", digits = 4, align = "c", col.names = c("Lek", "$\\alpha$", "$T_L$", "$T_U$"))

```

Otrzymane w [tabeli](#tabela1) przedziały ufności dla średniego czasu do remisji są identyczne i nie pozwalają na odróżnienie skuteczności leków A i B.
Jest to spowodowane faktem, że w obu grupach odnotowano taką samą liczbę nieocenzurowanych zdarzeń ($R_A = R_B$), przy tych samych $n$ oraz $t$.

## Zadanie 2

```{r obserwacja_10,echo = TRUE}
fun <- function(X, m, n, alpha) {
  Xs <- sort(X)
  T2 <- sum(Xs[1:m]) + (n - m)*Xs[m]
  theta.hat <- m/T2
  mi.hat <- 1/theta.hat
  
  q.m.1 <- qgamma(alpha / 2, shape = m, rate = m)
  q.m.2 <- qgamma(1 - alpha / 2, shape = m, rate = m)
  
  T.L <- m*q.m.1/T2
  T.U <- m*q.m.2/T2
  
  return(list(
    theta.hat = theta.hat,
    mi.hat = mi.hat,
    TL = T.L, TU = T.U
  ))
}


```

### Tabela oszacowania {#tabela2}
```{r tabela_oszacowania, results='asis', echo=FALSE}
library(knitr)

A_al1 <- fun(X_A, 10, 20, 0.05)
A_al2 <- fun(X_A, 10, 20, 0.01)
B_al1 <- fun(X_B, 10, 20, 0.05)
B_al2 <- fun(X_B, 10, 20, 0.01)

results <- data.frame(
  Lek = rep(c("A", "B"), each = 2),
  alpha = rep(c(0.05, 0.01), times = 2),
  theta_hat = c(A_al1$theta.hat, A_al2$theta.hat, B_al1$theta.hat, B_al2$theta.hat),
  mu_hat = c(A_al1$mi.hat, A_al2$mi.hat, B_al1$mi.hat, B_al2$mi.hat),
  T_L = c(A_al1$TL, A_al2$TL, B_al1$TL, B_al2$TL),
  T_U = c(A_al1$TU, A_al2$TU, B_al1$TU, B_al2$TU)
)

results[,3:6] <- lapply(results[,3:6], function(x) round(x, 4))


kable(results, caption = "Oszacowania parametrów $\\hat{\\theta}$ i $\\hat{\\mu}$ oraz przedziały ufności [$T_L$, $T_U$] dla leków A i B", col.names = c("Lek", "$\\alpha$", "$\\hat{\\theta}$", "$\\hat{\\mu}$", "$T_L$", "$T_U$"))

```

Średni czas do [remisji](#tabela2) ($\hat\mu$) jest krótszy dla leku B (`r round(B_al1$mi.hat,4)`) niż dla leku A (`r round(A_al1$mi.hat, 4)`), co sugeruje, że lek B może działać szybciej.
Jednak przedziały ufności dla obu leków są dość szerokie i częściowo się pokrywają, więc różnice nie są jednoznaczne.
Warto zauważyć, że w zależności od przyjętego typu cenzurowania wnioski mogą się różnić.
Przy założeniu cenzurowania I-go typu lek A wydaje się nieco lepszy, natomiast przy cenzurowaniu II-go typu lepsze wyniki uzyskuje lek B.

## Zadanie 3

```{r sym_bias_mse, echo = TRUE}

set.seed(123)
M <- 10000
theta <- 1
t.values <- c(0.5, 1, 2)
n.values <- c(10, 30)

gen1 <- function(n, alpha=1, lambda=theta, t0){
  y <- runif(n)
  x <- - (1/lambda)*log(1- y^(1/alpha))
  
  delta <- ifelse(x <= t0, 1, 0)
  x_obs <- pmin(x, t0)
  
  return(data.frame(x = x_obs, delta = delta))
}

symulacja <- function(n, t0, theta){
  repeat {
    X <- gen1(n, t0=t0, lambda=theta)
    R <- sum(X$delta)
    if (R < n) break  # akceptujemy tylko próby, gdzie jest cenzurowanie
  }
  T1 <- sum(X$x[which(X$delta ==1)]) + t0*(n - R)
  
  theta.hat <- R/T1
  theta.wave <- - log(1 - R/n)/t0
  
  return(c(theta.hat, theta.wave))
}

results <- data.frame(
  n = numeric(),
  t0 = numeric(),
  Bias_hat = numeric(),
  MSE_hat = numeric(),
  Bias_wave = numeric(),
  MSE_wave = numeric()
)

for (n in n.values) {
  for (t0 in t.values) {
    
    est <- replicate(M, symulacja(n, t0, theta))
    
    theta.hat <- est[1, ]
    theta.wave <- est[2, ]
    
    bias.hat <- mean(theta.hat - theta)
    mse.hat  <- mean((theta.hat - theta)^2)
    
    bias.wave <- mean(theta.wave - theta)
    mse.wave  <- mean((theta.wave - theta)^2)
    
   
    results <- rbind(results, data.frame(
      n = n,
      t0 = t0,
      Bias_hat = bias.hat,
      MSE_hat = mse.hat,
      Bias_wave = bias.wave,
      MSE_wave = mse.wave
    ))
  }
}

```
### Tabela bias mse {#tabela3}
```{r tabela_bias_mse, echo=FALSE}
kable(results, caption = "Oszacowania obciążenia odraz błędów średniokwadratowych dla $\\hat{\\theta}$ oraz $\\tilde{\\theta}$",
    col.names = c("$n$", "$t_0$", "$\\text{Bias}(\\hat{\\theta},\\theta)$",
    "$\\text{MSE}(\\hat{\\theta},\\theta)$",
    "$\\text{Bias}(\\tilde{\\theta},\\theta)$",
    "$\\text{MSE}(\\tilde{\\theta},\\theta)$"), digits = 4, align = "c")
```

W [przeprowadzonych symulacjach](#tabela3) zauważalne jest, że wraz ze wzrostem liczby obserwacji $n$ zarówno obciążenia, jak i błędy średniokwadratowe dla obu estymatorów systematycznie maleją, co wskazuje na poprawę ich dokładności.
Zauważalne jest jednak to, że estymator $\hat\theta$ wypada korzystniej w porównaniu z estymatorem $\tilde\theta$, gdyż charakteryzuje się mniejszym obciążeniem oraz niższymi wartościami MSE.

# Lista 4

## Zadanie 1

Dysponujemy danymi cenzurowanymi I-go typu, które są realizacjami zmiennych losowych z rozkładu wykładniczego.
Poniżej znajduje się zadeklarowana funkcja, której wartością dla tego typu danych jest wartość poziomu krytycznego w teście ilorazu wiarogodności do testowania hipotez dwustronnych, lewostronnych oraz prawostronnych.

```{r p-value,echo = TRUE}
wart_poz_kryt <- function(r, s, n, t0, theta0, rodzaj = "two.sided"){
  
  theta_hat <- r /(s + t0*(n-r))

  
  L <- function(theta){
    L <- (theta^r)*exp(-theta*(s + t0*(n-r)))
    return(L)
  }
  
  L_hat <- L(theta_hat)
  L_theta0 <- L(theta0)
  
  
  if (rodzaj=="two.sided"){
    lambda_obs <- L_theta0 / L_hat # funkcja osiąga sup dla est. MLE
  } else if (rodzaj == "less") {
    if (theta_hat < theta0){
      lambda_obs <- L_theta0 / L_hat 
    } else {
      lambda_obs <- 1
    }
  } else {
    if (theta_hat > theta0){
      lambda_obs <- L_theta0 / L_hat 
    } else {
      lambda_obs <- 1
    }
  }
  
  p_value <-1 - pchisq(-2*log(lambda_obs), df = 1)
  
  return (p_value)
  
}

```

## Zadanie 2

```{r moc_rozmiar, cache=TRUE,echo = TRUE}
set.seed(123)
M <- 10000
theta0 <- 1/2
n <- c(20,50)
t0 <- 2
theta <- c(0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.5, 2)

gen1 <- function(n, alpha=1, lambda=theta, t0){
  y <- runif(n)
  x <- - (1/lambda)*log(1- y^(1/alpha))
  
  delta <- ifelse(x <= t0, 1, 0)
  x_obs <- pmin(x, t0)
  
  return(data.frame(x = x_obs, delta = delta))
}


wyniki <- list()

for (n in n) {
  moc <- numeric(length(theta))
  p_val <- numeric(M)

for (k in seq_along(theta)){
  lambda <- theta[k]
  
  for (j in 1:M){
    x_wylos <- gen1(n=n, lambda=lambda, t0 = t0)
    x_obs <- x_wylos$x
    r <- sum(x_wylos$delta)
    s <- sum(x_wylos$x[x_wylos$delta==1])
    p_val[j] <- wart_poz_kryt(r=r, s=s, n=n, t0=t0, 
                              theta0=theta0, rodzaj = "two.sided")
  }
  moc[k] <- 1/M * sum(p_val[1:M]<0.05) 
}
  p_val_theta0 <- numeric(M)
  for (j in 1:M){
    x_wylos <- gen1(n = n, lambda = theta0, t0 = t0)
    r <- sum(x_wylos$delta)
    s <- sum(x_wylos$x[x_wylos$delta == 1])
    p_val_theta0[j] <- wart_poz_kryt(r = r, s = s, n = n, t0 = t0,
                                     theta0 = theta0, rodzaj = "two.sided")
  }
  
  rozmiar_hat <- mean(p_val_theta0 < 0.05)
  
  wyniki[[paste0("n=", n)]] <- data.frame(theta = theta, moc = moc)
}

```

### Tabela mocy {#moc}
```{r tabela_mocy, echo=FALSE}
library(dplyr)
tabela_mocy <- wyniki[["n=20"]] %>%
  rename(moc_n20 = moc) %>%
  left_join(
    wyniki[["n=50"]] %>% rename(moc_n50 = moc),
    by = "theta"
  )

tabela_mocy <- tabela_mocy %>%
  mutate(
    moc_n20 = round(moc_n20, 4),
    moc_n50 = round(moc_n50, 4)
  )

kable(
  tabela_mocy,
  caption = "Porównanie mocy testu dla różnych wartości $\\theta$ i liczebności prób (n = 20, 50)",
  col.names = c("$\\theta$", "Moc (n = 20)", "Moc (n = 50)"), align = "c")


```

Na podstawie [wyników](#moc) symulacji możemy zauważyć, że wartości oszacowania mocy są wyższe dla $n = 50$ niż dla $n = 20$ dla każdego $\theta \neq \theta_0$, co oznacza, że zwiększenie liczby obserwacji poprawia zdolność testu do wykrywania rzeczywistych różnic w parametrze.

Korzystając ze wzoru pokazanego na Wykładzie 4 tj.

$$\beta_\varphi = \sup_{\vartheta \in \Theta_0} \beta_\varphi(\vartheta)$$ gdzie $\beta_\varphi(\vartheta)$ oznacza funkcję mocy testu $\varphi$,

otrzymujemy rozmiar testu.
W przypadku hipotezy dwustronnej oznacza to, że sprawdzamy wartość oszacowania mocy testu dla $\theta = \theta_0$.
U nas: dla $n = 20$ rozmiar testu wynosi `r tabela_mocy$moc_n20[tabela_mocy$theta == theta0]` natomiast dla $n = 50$ jest on równy `r tabela_mocy$moc_n20[tabela_mocy$theta == theta0]`.

## Zadanie 3

```{r weryf_hipotezy,echo  = TRUE}
czasy_A <- c(0.03345514, 0.08656403, 0.08799947, 0.24385821, 
             0.27755032, 0.40787247, 0.58825664, 0.64125620,
             0.90679161, 0.94222208, rep(1, 10))

czasy_B <- c(0.03788958, 0.12207257, 0.20319983, 0.24474299,
             0.30492413, 0.34224462, 0.42950144, 0.44484582,
             0.63805066, 0.69119721, rep(1, 10))

s_A <- sum(czasy_A[1:10])
r <- 10
s_B <- sum(czasy_B[1:10])
n <- 20
t0 <- 1
theta0 <- 1

p_wart_A <- wart_poz_kryt(r=r, s=s_A, n=n, t0=t0, 
                          theta0=theta0, rodzaj="two.sided")
p_wart_B <- wart_poz_kryt(r=r, s=s_B, n=n, t0=t0, 
                          theta0=theta0, rodzaj="two.sided")

```

Dla danych dotyczących leku A otrzymano wartość p-value równą\
$p_A = `r round(p_wart_A, 4)`$, natomiast dla leku B $p_B = `r round(p_wart_B, 4)`$.\
Przy poziomie istotności $\alpha = 0.05$ w obu przypadkach $p > \alpha$, dlatego nie ma podstaw do odrzucenia hipotezy zerowej $H_0: \theta = 1$.\
Oznacza to, że nie ma statystycznie istotnych dowodów na to, że średni czas do remisji choroby w grupie A lub w grupie B różni się od $1$.
